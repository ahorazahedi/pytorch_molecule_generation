{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import rdkit\n",
    "from rdkit.Chem.rdmolfiles import SmilesMolSupplier\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from Parameters import Parameters as C\n",
    "\n",
    "from MolecularGraph import PreprocessingGraph\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/test.smi') as smi_file:\n",
    "    first_line = smi_file.readline()\n",
    "    has_header = bool(\"SMILES\" in first_line)\n",
    "smi_file.close()\n",
    "\n",
    "# read file\n",
    "molecule_set = SmilesMolSupplier('./data/test.smi', sanitize=True, nameColumn=-1, titleLine=has_header)\n",
    "\n",
    "number_of_molecule = len(molecule_set)\n",
    "def get_graph(mol):\n",
    "    \n",
    "    if mol is not None:\n",
    "        if not C.use_aromatic_bonds:\n",
    "            rdkit.Chem.Kekulize(mol, clearAromaticFlags=True)\n",
    "        molecular_graph = PreprocessingGraph(molecule=mol, constants=C)\n",
    "\n",
    "        return molecular_graph\n",
    "\n",
    "\n",
    "def calculate_reversing_decode_route_length(molecular_graph):\n",
    "    \n",
    "    return molecular_graph.get_n_edges() + 2\n",
    "\n",
    "n_subgraphs = 0  \n",
    "molecular_graph_generator = map(get_graph, molecule_set)\n",
    "\n",
    "\n",
    "# for molecular_graph in tqdm(molecular_graph_generator , total=number_of_molecule):\n",
    "#     n_SGs = calculate_reversing_decode_route_length(molecular_graph=molecular_graph)\n",
    "#     n_subgraphs += n_SGs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subgraphs = 7336931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_dims():\n",
    "\n",
    "    dims = {}\n",
    "    dims[\"nodes\"] = C.dim_nodes\n",
    "    dims[\"edges\"] = C.dim_edges\n",
    "    dims[\"APDs\"] = [np.prod(C.dim_f_add) + np.prod(C.dim_f_conn) + 1]\n",
    "    return dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"nodes\", \"edges\", \"APDs\"]\n",
    "dims = get_dataset_dims()\n",
    "\n",
    "\n",
    "def create_datasets(hdf_file, max_length, dataset_name_list, dims):\n",
    "    ds = {}\n",
    "\n",
    "    for ds_name in dataset_name_list:\n",
    "        ds[ds_name] = hdf_file.create_dataset(ds_name,\n",
    "                                              (max_length, *dims[ds_name]),\n",
    "                                              chunks=True,\n",
    "                                              dtype=np.dtype(\"int8\"))\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_group(dataset_dict, data_subgraphs, data_APDs, n_SGs, init_idx):\n",
    "\n",
    "    nodes = np.array([graph_tuple[0] for graph_tuple in data_subgraphs])\n",
    "    edges = np.array([graph_tuple[1] for graph_tuple in data_subgraphs])\n",
    "    APDs = np.array(data_APDs)\n",
    "\n",
    "    end_idx = init_idx + n_SGs \n",
    "\n",
    "    dataset_dict[\"nodes\"][init_idx:end_idx] = nodes\n",
    "    dataset_dict[\"edges\"][init_idx:end_idx] = edges\n",
    "    dataset_dict[\"APDs\"][init_idx:end_idx] = APDs\n",
    "\n",
    "    return dataset_dict\n",
    "\n",
    "\n",
    "def get_graph(mol):\n",
    "    \n",
    "    if mol is not None:\n",
    "        if not C.use_aromatic_bonds:\n",
    "            rdkit.Chem.Kekulize(mol, clearAromaticFlags=True)\n",
    "        molecular_graph = PreprocessingGraph(molecule=mol, constants=C)\n",
    "\n",
    "        return molecular_graph\n",
    "\n",
    "def generate_decoding_states(molecular_graph, subgraph_idx):\n",
    "\n",
    "    molecular_graph = copy.deepcopy(molecular_graph)\n",
    "\n",
    "    if subgraph_idx != 0:\n",
    "        \n",
    "        for _ in range(1, subgraph_idx):\n",
    "            molecular_graph.truncate_graph()\n",
    "            \n",
    "        decoding_APD = molecular_graph.get_decoding_APD()\n",
    "        molecular_graph.truncate_graph()\n",
    "        \n",
    "        X, E = molecular_graph.get_graph_state()\n",
    "        \n",
    "    elif subgraph_idx == 0:\n",
    "        \n",
    "        decoding_APD = molecular_graph.get_final_decoding_APD()\n",
    "        \n",
    "        X, E = molecular_graph.get_graph_state()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"`subgraph_idx` not a valid value.\")\n",
    "\n",
    "    decoding_graph = [X, E]\n",
    "    return decoding_graph, decoding_APD\n",
    "def group_subgraphs(init_idx, molecule, dataset_dict):\n",
    "   \n",
    "    data_subgraphs = []        \n",
    "    data_APDs = []           \n",
    " \n",
    "    molecular_graph_generator = get_graph(molecule)\n",
    "\n",
    "    molecules_processed = 0 \n",
    "    \n",
    "    for graph in [molecular_graph_generator]:\n",
    "      \n",
    "        molecules_processed += 1\n",
    "\n",
    "        n_SGs = calculate_reversing_decode_route_length(molecular_graph=graph)\n",
    "\n",
    "        for new_SG_idx in range(n_SGs):  \n",
    "            \n",
    "            SG, APD = generate_decoding_states(molecular_graph=graph,\n",
    "                                                   subgraph_idx=new_SG_idx)\n",
    "            data_subgraphs.append(SG)\n",
    "            data_APDs.append(APD)\n",
    "          \n",
    "    dataset_dict = save_group(dataset_dict=dataset_dict,\n",
    "                              n_SGs=n_SGs,\n",
    "                              data_subgraphs=data_subgraphs,\n",
    "                              data_APDs=data_APDs,\n",
    "                              init_idx=init_idx)\n",
    "\n",
    "    len_data_subgraphs = len(data_subgraphs)\n",
    "    return molecules_processed, dataset_dict, len_data_subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk File Already exist Removing Previous Chunk File\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f\"./train.h5.chunked\"):\n",
    "        print(\"Chunk File Already exist Removing Previous Chunk File\")\n",
    "        os.remove(f\"./train.h5.chunked\")\n",
    "        \n",
    "# with h5py.File(f\"./train.h5.chunked\", \"a\") as hdf_file:\n",
    "#         print(\"Creating HDF File To Store APDs\")\n",
    "        \n",
    "#         ds = create_datasets(hdf_file=hdf_file,\n",
    "#                                 max_length=n_subgraphs,\n",
    "#                                 dataset_name_list=dataset_names,\n",
    "#                                 dims=dims)\n",
    "        \n",
    "\n",
    "#         dataset_size = 0  \n",
    "#         for init_idx in tqdm(range(30, number_of_molecule)):\n",
    "                \n",
    "#                 (final_molecule_idx, ds, len_data_subgraphs) = group_subgraphs(init_idx=init_idx,\n",
    "#                                                 molecule=molecule_set[init_idx],\n",
    "#                                                 dataset_dict=ds,                                           \n",
    "#                                                 )\n",
    "            \n",
    "#                 dataset_size += len_data_subgraphs\n",
    "        # print(\"Start Looping Over Molecules\")\n",
    "        # for init_idx in tqdm(range(0, number_of_molecule)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_threads = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating HDF File To Store APDs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/29055 [00:34<18:50:39,  2.34s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     p\u001b[39m.\u001b[39mstart()\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m processes:\n\u001b[0;32m---> 15\u001b[0m     p\u001b[39m.\u001b[39;49mjoin()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popen\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/multiprocessing/popen_fork.py:43\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[39m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpoll(os\u001b[39m.\u001b[39;49mWNOHANG \u001b[39mif\u001b[39;49;00m timeout \u001b[39m==\u001b[39;49m \u001b[39m0.0\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m0\u001b[39;49m)\n\u001b[1;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/multiprocessing/popen_fork.py:27\u001b[0m, in \u001b[0;36mPopen.poll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         pid, sts \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mwaitpid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpid, flag)\n\u001b[1;32m     28\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[39m# Child process not yet created. See #1731717\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[39m# e.errno == errno.ECHILD == 10\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/29055 [00:57<20:02:50,  2.49s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_range(start, end, hdf_file_path, molecule_set, dataset_dict , shared_counter):\n",
    "    dataset_size = 0\n",
    "    for init_idx in range(start, end):\n",
    "        final_molecule_idx, ds, len_data_subgraphs = group_subgraphs(\n",
    "            init_idx=init_idx,\n",
    "            molecule=molecule_set[init_idx],\n",
    "            dataset_dict=dataset_dict,\n",
    "        )\n",
    "        with shared_counter.get_lock():\n",
    "            shared_counter.value += 1\n",
    "        dataset_size += len_data_subgraphs\n",
    "    # Additional processing if needed\n",
    "    return dataset_size\n",
    "\n",
    "\n",
    "def tqdm_thread(counter, total):\n",
    "    pbar = tqdm(total=total)\n",
    "    while True:\n",
    "        pbar.n = counter.value\n",
    "        pbar.refresh()\n",
    "        if pbar.n >= total:\n",
    "            break\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "# manager = Manager()\n",
    "# shared_counter = manager.Value('i', 0)\n",
    "\n",
    "# # Create and start tqdm thread\n",
    "# tqdm_thread = threading.Thread(target=tqdm_thread, args=(shared_counter, end - start))\n",
    "# tqdm_thread.start()\n",
    "\n",
    "\n",
    "# with h5py.File(f\"./train.h5.chunked\", \"a\") as hdf_file:\n",
    "#     print(\"Creating HDF File To Store APDs\")\n",
    "#     ds = create_datasets(hdf_file=hdf_file, max_length=n_subgraphs, dataset_name_list=dataset_names, dims=dims)\n",
    "\n",
    "#     # Split the range into 4 parts\n",
    "#     range_splits = [(i * number_of_molecule // n_threads, (i + 1) * number_of_molecule // n_threads) for i in range(n_threads)]\n",
    "\n",
    "#     processes = []\n",
    "#     for start, end in range_splits:\n",
    "#         p = Process(target=process_range, args=(start, end, hdf_file.filename, molecule_set, ds))\n",
    "#         processes.append(p)\n",
    "#         p.start()\n",
    "\n",
    "#     for p in processes:\n",
    "#         p.join()\n",
    "manager = Manager()\n",
    "shared_counter = manager.Value('i', 0)\n",
    "\n",
    "with h5py.File(\"./train.h5.chunked\", \"a\") as hdf_file:\n",
    "    print(\"Creating HDF File To Store APDs\")\n",
    "    ds = create_datasets(hdf_file=hdf_file, max_length=n_subgraphs, dataset_name_list=dataset_names, dims=dims)\n",
    "\n",
    "    range_splits = [(i * number_of_molecule // n_threads, (i + 1) * number_of_molecule // n_threads) for i in range(n_threads)]\n",
    "\n",
    "    processes = []\n",
    "    for start, end in range_splits:\n",
    "        p = Process(target=process_range, args=(start, end, hdf_file.filename, molecule_set, ds, shared_counter))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # Start the tqdm thread\n",
    "    tqdm_thread_instance = threading.Thread(target=tqdm_thread, args=(shared_counter, number_of_molecule))\n",
    "    tqdm_thread_instance.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    # Ensure the tqdm thread is also joined after all processes complete\n",
    "    tqdm_thread_instance.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "i = 0\n",
    "with Chem.MultithreadedSDMolSupplier('./data/test.smi') as sdSupl:\n",
    "  for mol in sdSupl:\n",
    "    \n",
    "    \n",
    "    if mol is not None:\n",
    "      i += 1\n",
    "# with Chem.MultithreadedSDMolSupplier('./data/test.smi') as sdSupl:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "molecule_set = SmilesMolSupplier('./data/test.smi', sanitize=True, nameColumn=-1, titleLine=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7fb16c6d93c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecule_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
